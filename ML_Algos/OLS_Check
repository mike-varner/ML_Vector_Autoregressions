#Import Packages
import numpy
import pandas
from sklearn.cross_validation import KFold
from sklearn.grid_search import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import Lasso
from sklearn import linear_model
from sklearn.linear_model import LassoCV

"""
Stage 1: Import and Clean Data
"""
#import data
qe_data = pandas.read_csv('/Users/Mike/Desktop/Bates Files/Senior Year/Thesis/QE_Data/qe_data.csv', low_memory=False)
#remove date variable
date = pandas.DataFrame(qe_data, columns=['date'])
x = qe_data.drop('date', 1)
#create list of exogeneous variable names 
exogeneous_var_names = ['money_supply', 'tax_rev', 'federal_debt', 'gov_exp', 'broad_index', 'financial_stress', 'industrial_production']
#remove exogeneous variables
endogeneous = x.drop(exogeneous_var_names, 1)
#create a list of the endogeneous variable names
endogeneous_variable_names = list(endogeneous.columns.values)

#create data without lags to use in variance/covariance calculation below
clean_data_with_out_lags = endogeneous.dropna(how='any')


#set the maximum number of lags that the model can consider for variable selection and estimation
#I have arbitrairly chose twice as many lags as endogeneous variables
max_lags = int(len(endogeneous_variable_names)+1)
lags = (range(max_lags))[1:]

#create lagged values of the endogeneous variables
for p in lags:
    for var in endogeneous_variable_names:
        endogeneous["L{0}_{1}".format(p , var)] = endogeneous[var].shift(p)

#add back in the exogeneous variables
#prepared_data = endogeneous.add(exogeneous)

#remove missing values created by creating lags
#this might not be what I want, but come back to it later
clean_data = endogeneous.dropna(how='any') 



"""
Stage 2: Compute Matricies Using LASSO
"""
####Calculate the Y matrix (KxT) or (4x545)
Y = clean_data[endogeneous_variable_names].transpose()
Y.as_matrix()

'''Calculate B using OLS row by row
'''
#define the model 
ols = linear_model.LinearRegression()

#fit a regression using all data except current value
fed_funds_ols = ols.fit(clean_data.drop(endogeneous_variable_names, 1) , clean_data.fed_funds.as_matrix())
fed_funds_ols_coeff = fed_funds_ols.coef_
unemployment_ols = ols.fit(clean_data.drop(endogeneous_variable_names, 1) , clean_data.unemployment.as_matrix())
unemployment_ols_coeff = unemployment_ols.coef_
treasury_bill_ols = ols.fit(clean_data.drop(endogeneous_variable_names, 1) , clean_data.treasury_bill.as_matrix())
treasury_bill_ols_coeff = treasury_bill_ols.coef_
qe_ols = ols.fit(clean_data.drop(endogeneous_variable_names, 1), clean_data.qe.as_matrix())
qe_ols_coeff = qe_ols.coef_


B = treasury_bill_ols_coeff
#append rows of coefficients 
B = numpy.vstack([qe_ols_coeff,B])
B = numpy.vstack([unemployment_ols_coeff,B])
B = numpy.vstack([fed_funds_ols_coeff,B])
B = pandas.DataFrame(B)

#####PUT INTO SPACE STATE NOTATION#####
#create a new coefficient matrix which is (npxnp) or (16x16)
I_4 = numpy.identity(12)
zero_columns = numpy.zeros((12,4))
add_on = numpy.column_stack((I_4,zero_columns))

#append add_on to to B to get B_Space_State
B_Row_OLS_Space_State = pandas.DataFrame(numpy.append(B,add_on, axis=0))



'''Calculate B using OLS formula B = YZ'(ZZ')^âˆ’1  pg.72 Lutkehpol
'''
####Calculate the Z matrix ((Kp+1)xT)#### or (17x545)
#swap the rows and colummns of the clean_data matrix 
transpose_of_clean = clean_data.drop(endogeneous_variable_names, 1).transpose()
#number of observatiosn, or columns
T = float(len(transpose_of_clean.columns))
#create a (1xT) row of 1s to add into the Z matrix
row_of_ones = numpy.ones((T,), dtype=np.int)
#add row of ones as the first column in transpose_of_clean
Z = numpy.vstack((row_of_ones,transpose_of_clean.as_matrix()))
Z = pandas.DataFrame(Z)


ZZ_inverse = numpy.linalg.inv(numpy.matmul(Z,Z.transpose()))
YZ_prime = numpy.matmul(Y,Z.transpose())
B_OLS = pandas.DataFrame(numpy.matmul(YZ_prime,ZZ_inverse))

#remove the first column which is the intercept column
B = B_OLS.drop(B_OLS.columns[[0]], axis=1) 

#put into space state to check if it works
I_4 = numpy.identity(12)
zero_columns = numpy.zeros((12,4))
add_on = numpy.column_stack((I_4,zero_columns))

#append add_on to to B to get B_Space_State
B_Lutkehopl_Space_State = pandas.DataFrame(numpy.append(B,add_on, axis=0))




#calculate the variance/covariance matrix using numpy
Sigma = pandas.DataFrame(numpy.cov(clean_data_with_out_lags,rowvar=False))




#orthogonalize Sigma by imposing off diagonals are 0
diag_sigma = pandas.DataFrame(numpy.diag(np.diag(Sigma)))
#calculate cholesky decomposistion of sigma
chol_of_sigma = pandas.DataFrame(numpy.linalg.cholesky(diag_sigma))
#define the inverse of the cholesky decomposistion of sigma to use below
inverse_chol = numpy.linalg.inv(chol_of_sigma)

####Calculate Space-State version of the Q matrix
zero_columns = numpy.zeros((12,4))
zeros_16x12 = numpy.zeros((16,12))
#append add_on to to Sigma to get Q_Space_State
Q_Space_State = pandas.DataFrame(numpy.append(inverse_chol,zero_columns, axis=0))
Q_Space_State = pandas.DataFrame(numpy.column_stack((Q_Space_State,zeros_16x12)))




'''Calculate IRs
'''
#create impulse column vector (TX1)
e_feddunds = pandas.DataFrame(numpy.vstack((1,numpy.zeros(((15),1)))))
e_qe = pandas.DataFrame(numpy.vstack((numpy.vstack((numpy.zeros((2, 1)),1)),numpy.zeros((13,1)))))

e_0 = e_qe


#run shock e_0 through system
Q_e = pandas.DataFrame(numpy.matmul(Q_Space_State,e_0))


for p in range(1,21):
    globals()['point_estimate_{}'.format(p)] = pandas.DataFrame(numpy.matmul(Q_Space_State, numpy.matmul(numpy.linalg.matrix_power(B_Space_State, p),Q_e)))


impulse_qe_var = pandas.DataFrame(numpy.column_stack((Q_e,point_estimate_1)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_2)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_3)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_4)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_5)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_6)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_7)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_8)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_9)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_10)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_11)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_12)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_13)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_14)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_15)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_16)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_17)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_18)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_19)))
impulse_qe_var = pandas.DataFrame(numpy.column_stack((impulse_qe_var,point_estimate_20)))


#this is really messed up : doesn't look remotely correct
imp_qe_response_unemp = pandas.DataFrame(impulse_qe_var.loc[1:1].transpose())

