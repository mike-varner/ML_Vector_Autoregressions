#Import Packages
import numpy
import pandas
from sklearn.cross_validation import KFold
from sklearn.grid_search import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import Lasso
from sklearn import linear_model
from sklearn.linear_model import LassoCV

"""
Stage 1: Import and Clean Data
"""
#import data
qe_data = pandas.read_csv('/Users/Mike/Desktop/Bates Files/Senior Year/Thesis/QE_Data/qe_data.csv', low_memory=False)
#remove date variable
date = pandas.DataFrame(qe_data, columns=['date'])
x = qe_data.drop('date', 1)
#create list of exogeneous variable names 
exogeneous_var_names = ['money_supply', 'tax_rev', 'federal_debt', 'gov_exp', 'broad_index', 'financial_stress', 'industrial_production']
#remove exogeneous variables
endogeneous = x.drop(exogeneous_var_names, 1)
#create a list of the endogeneous variable names
endogeneous_variable_names = list(endogeneous.columns.values)
#create dataframe of exogeneous variables
exogeneous = x.drop(endogeneous_variable_names, 1)

#set the maximum number of lags that the model can consider for variable selection and estimation
#I have arbitrairly chose twice as many lags as endogeneous variables
max_lags = int(len(endogeneous_variable_names)*2+1)
lags = (range(max_lags))[1:]

#create lagged values of the endogeneous variables
for p in lags:
    for var in endogeneous_variable_names:
        endogeneous["L{0}_{1}".format(p , var)] = endogeneous[var].shift(p)

#add back in the exogeneous variables
#prepared_data = endogeneous.add(exogeneous)

#remove missing values created by creating lags
#this might not be what I want, but come back to it later
clean_data = endogeneous.dropna(how='any') 

"""
Stage 2: Compute Matricies Using LASSO
"""
####Calculate the Y matrix (KxT)
Y = clean_data[endogeneous_variable_names].transpose()
Y.as_matrix()

###Calculate B Matrix (k*(kp+1))####
#define the LASSO with 10 KFold CV, to calculate coefficients and intercepts
lasso = linear_model.LassoCV(cv=10, n_jobs=-1 , normalize=True)
'''
#fit the LASSO only using lagged values of the endogeneous variables
qe_lasso = lasso.fit(clean_data.drop(endogeneous_variable_names, 1).as_matrix() , clean_data.qe.as_matrix())
#strip the coefficients from the LASSO
#add the intercept to the beginning of the array
qe_lasso_coeff = numpy.hstack((qe_lasso.intercept_, qe_lasso.coef_))
'''

fed_funds_lasso = lasso.fit(clean_data.drop(endogeneous_variable_names, 1).as_matrix() , clean_data.fed_funds.as_matrix())
fed_funds_lasso_coeff = numpy.hstack((fed_funds_lasso.intercept_, fed_funds_lasso.coef_))
unemployment_lasso = lasso.fit(clean_data.drop(endogeneous_variable_names, 1).as_matrix() , clean_data.unemployment.as_matrix())
unemployment_lasso_coeff = numpy.hstack((unemployment_lasso.intercept_, unemployment_lasso.coef_))
treasury_bill_lasso = lasso.fit(clean_data.drop(endogeneous_variable_names, 1).as_matrix() , clean_data.treasury_bill.as_matrix())
treasury_bill_lasso_coeff = numpy.hstack((treasury_bill_lasso.intercept_, treasury_bill_lasso.coef_))
qe_lasso = lasso.fit(clean_data.drop(endogeneous_variable_names, 1).as_matrix() , clean_data.qe.as_matrix())
qe_lasso_coeff = numpy.hstack((qe_lasso.intercept_, qe_lasso.coef_))

#initialize the first row of the B matrix as fed_funds coefficients
B = fed_funds_lasso_coeff
#append rows of coefficients 
B = numpy.vstack([unemployment_lasso_coeff,B])
B = numpy.vstack([qe_lasso_coeff,B])
B = numpy.vstack([treasury_bill_lasso_coeff,B])
B = pandas.DataFrame(B)

'''
B = fed_funds_lasso_coeff
for var in endogeneous_variable_names:
    globals()['lasso_'+str(var)] = lasso.fit(clean_data.drop(endogeneous_variable_names, 1).as_matrix(), clean_data[var].as_matrix())
    globals()['coeff_lasso_'+str(var)] = numpy.hstack((globals()['lasso_'+str(var)].intercept_, 'lasso_'+str(var)].coef_))
    B_loop = numpy.vstack(globals()['coeff_lasso_'+str(var)],B])
'''

####Calculate the Z matrix ((Kp+1)xT)####
#swap the rows and colummns of the clean_data matrix 
transpose_of_clean = clean_data.drop(endogeneous_variable_names, 1).transpose()
#number of observatiosn, or columns
T = float(len(transpose_of_clean.columns))
#create a (1xT) row of 1s to add into the Z matrix
row_of_ones = numpy.ones((T,), dtype=np.int)
#add row of ones as the first column in transpose_of_clean
Z = numpy.vstack((row_of_ones,transpose_of_clean.as_matrix()))
Z = pandas.DataFrame(Z)

####Calculate the Gamma matrix ((Kp+1)x(Kp+1))
Gamma = numpy.matmul(Z,Z.transpose())/T
Gamma = pandas.DataFrame(Gamma)

####Calculate the residual matrix U (KxT)
Y_hat = numpy.matmul(B,Z) #should be (KxT)
U = Y-Y_hat

####Calculate Sigma matrix (TxT)
one_over_T = float(1/T)
Sigma_E = numpy.matmul(U.transpose(),U)*one_over_T
Sigma_E = pandas.DataFrame(Sigma_E)


'''
'''
#orthogonalize Sigma by imposing off diagonals are 0
diag_sigma = pandas.DataFrame(numpy.diag(np.diag(Sigma_E)))
#calculate cholesky decomposistion of sigma
chol_of_sigma = pandas.DataFrame(numpy.linalg.cholesky(diag_sigma))
chol_of_sigma_e_transpose = pandas.DataFrame(chol_of_sigma.transpose())
#define the inverse of the cholesky decomposistion of sigma to use below
inverse_chol = numpy.linalg.inv(chol_of_sigma)


Sigma_U = pandas.DataFrame(numpy.diag(numpy.diag(numpy.linalg.cholesky(diag_sigma))))
A_Inverse = pandas.DataFrame(numpy.matmul(chol_of_sigma_e_transpose, numpy.linalg.inv(Sigma_U)))


#create impulse column vector (TX1) or 36x1
u_0 = pandas.DataFrame(numpy.vstack((1,numpy.zeros(((35),1)))))
z_0 = pandas.DataFrame(numpy.matmul(A_Inverse, u_0))

'''
Dimensions won't line up
'''










